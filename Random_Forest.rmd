---
title: "Random_forest"
author: "Nitin Arun Khandare"
date: "16 May 2018"
output: html_document
---

```{r setup, include=FALSE}
library(randomForest)
library(dplyr)
library(caret)
library(rattle)
library(rpart)
hr = read.csv('E:/Term 2/Machine Learning/Datasets/HR Analytics.csv')
knitr::opts_chunk$set(echo = TRUE)
```



### so here splitting/fiting the classification model using decisin tree
```{r}
hr = read.csv("E:/Term 2/Machine Learning/Datasets/HR Analytics.csv")

hr$Attrition = as.factor(hr$Attrition)

hr_train = hr[sample(seq(1,nrow(hr)),(0.7*nrow(hr))),]

hr_test = hr[sample(seq(1,nrow(hr)),(0.3*nrow(hr))),]

dim(hr_test)
dim(hr_train)

model = rpart::rpart(Attrition ~ X+MonthlyIncome+OverTime, data = hr_train)
fancyRpartPlot(model)
hr_test$predict = predict(model, hr_test)


hr[1189,c('X','OverTime','MonthlyIncome','Attrition')]


x = hr_train %>% filter(OverTime == 'Yes',MonthlyIncome>=3924)
table(x$Attrition)

## we testing model here using hr_test the predicted data is added in test
model = rpart(Attrition ~ X+MonthlyIncome+OverTime, data = hr_train)
fancyRpartPlot(model)


####### predicted in result
result = as.data.frame(predict(model, hr_test))
result

### created predicter using ifelse for 0 and 1

hr_test$predict = ifelse(result$`0`>0.5,0,1)

View(hr_test[, c('Attrition','predict')])

hr_test %>% filter(predict == Attrition) %>% nrow()

nrow(hr_test)

370/nrow(hr_test)


table(hr$Attrition)
```


```{r}
library(caret)
table(hr_test$predict,hr_test$Attrition)
hr_test %>% filter(Attrition==0, predict==0) %>% nrow()

hr_test %>% filter(Attrition == 1,predict == 0) %>% nrow()
```
```{r}
library(rattle)
model = rpart(Attrition~MonthlyIncome+OverTime, data = hr)

fancyRpartPlot(model)
```



```{r}
hr_train$Attrition = as.factor(hr_train$Attrition)
hr_test$Attrition <- as.factor(hr_test$Attrition)

model_rf1 = randomForest(Attrition~., data = hr_train)
result = as.data.frame(predict(model_rf1, hr_test))


hr_test$predict = ifelse(result$`0` >0.5,0,1)
hr_test$predict = as.factor(hr_test$predict)
confusionMatrix(hr_test$predict, hr_test$Attrition, positive = '1')

table(hr_train$Attrition)
858/nrow(hr_train)

```

## random forest model
```{r}

mtry1 = round(sqrt(length(colnames(hr_train))-1))
model_rf = randomForest(Attrition~., data = hr_train, mtree = 400, mtry = mtry)

hr_test$predicted = predict(model_rf , hr_test)


hr_test$predicted <- as.factor(hr_test$predicted)
hr_test$Attrition <- as.factor(hr_test$Attrition)

cm = confusionMatrix(hr_test$predicted, hr_test$Attrition,positive = '1')

cm$overall['Accuracy']*100
cm$byClass['Sensitivity']*100

```


#### for loop
```{r}
#### for loop
Accuracy = c()
Sensitivity= c()

#mtry:no.of predictor at a time
#ntree:no.of decision tree we want to grow
mtry = round(sqrt(length(colnames(hr))-1))
hr_train$Attrition <- as.factor(hr_train$Attrition)

cm_accr <- c()

for(i in (10:400)){

model_rf <- randomForest(Attrition~.,data=hr_train,mtry= mtry,mtree=i)
hr_test$predicted <- predict(model_rf,hr_test)

hr_test$predicted <- as.factor(hr_test$predicted)
hr_test$Attrition <- as.factor(hr_test$Attrition)

cm <- confusionMatrix(hr_test$predicted,hr_test$Attrition,positive = '1')
cm_accr <- c(cm_accr,cm$overall['Accuracy'])

}

names(cm_accr) <- NULL
View(cm_accr)
plot(cm_accr)
length(cm_accr)
df <- data.frame(x=1:391,y=cm_accr)
View(df)


```


## creatting multiple random forest for multiple tree ## mimiking random forest

### step by step creation of using bagging method
```{r}
## column selection for decision tree
input_predictor = colnames(hr_train %>% select(-Attrition))

## sqrt of all column total 
mtry = round(sqrt(length(input_predictor)))
mtree = 400

## created actual column from Attrition
result = data.frame(actual = hr_test$Attrition)


### loping the evry tree in forest
for(i in seq(1,mtree)){
  
  sample_predictors = input_predictor[sample(1:length(input_predictor),mtry)]
  
  
  sample_index = sample(seq(1,nrow(hr_train)), (0.6*nrow(hr_train)))
  
  sample_data = hr_train[sample_index, c(sample_predictors, 'Attrition')]
  curr_model = rpart(Attrition~., data = sample_data)
  result[,paste0('tree_',i , collapse = '')] = predict(curr_model, hr_test %>% 
                                                          select(sample_predictors),type = 'class')
  
}


###########   predicting base on pulling the specific data

result$count_0 = rowSums((result %>% select(-actual)) == 0)
result$count_1 = rowSums((result %>% select(-actual)) == 1)


##########  creating the separat column base on condtion on 0 and 1
result$final = ifelse(result$count_0>result$count_1,0,1)
```

```{r}
table(result$final, result$actual)


```



####### boosting algorithm in Random forest
```{r}
library(adabag)

model_boost = boosting(Attrition~., data = hr_train)

predict_obj = predict(model_boost, hr_test)

hr_test$pred  = predict_obj$class

hr_test$Attrition = as.factor(hr_test$Attrition)

hr_test$pred = as.factor(hr_test$pred)

confusionMatrix(hr_test$pred, hr_test$Attrition, positive = '1')
```

```{r}

```

